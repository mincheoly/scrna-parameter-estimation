{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77355663-3e78-4dbc-9112-8e87e6223773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate DE data\n",
    "\n",
    "#Generate DE data with 2 replicates\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "import scipy as sp\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.integrate import dblquad\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import statsmodels.api as sm\n",
    "import pickle as pkl\n",
    "import time\n",
    "import string\n",
    "import random\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "from statsmodels.stats.moment_helpers import cov2corr\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/ssm-user/Github/scrna-parameter-estimation/dist/memento-0.1.0-py3.10.egg')\n",
    "import memento\n",
    "import memento.simulate as simulate\n",
    "\n",
    "data_path = '/data_volume/memento/simulation/'\n",
    "\n",
    "\n",
    "### Setup simulation\n",
    "\n",
    "ifn_adata = sc.read('/data_volume/memento/hbec/' + 'HBEC_type_I_filtered_counts_deep.h5ad')\n",
    "q=0.07\n",
    "\n",
    "adata_1 = ifn_adata[(ifn_adata.obs['cell_type'] == 'ciliated') & (ifn_adata.obs['stim'] == 'control')]\n",
    "adata_2 = ifn_adata[(ifn_adata.obs['cell_type'] == 'ciliated') & (ifn_adata.obs['stim'] == 'beta')]\n",
    "\n",
    "x_param_1, z_param_1, Nc_1, good_idx_1 = simulate.extract_parameters(adata_1.X, q=q)\n",
    "x_param_2, z_param_2, Nc_2, good_idx_2 = simulate.extract_parameters(adata_2.X, q=q)\n",
    "common_set = np.array(list(set(good_idx_1) & set(good_idx_2)))\n",
    "x_param_1 = (\n",
    "    np.array([x for x,i in zip(x_param_1[0], good_idx_1) if i in common_set]),\n",
    "    np.array([x for x,i in zip(x_param_1[1], good_idx_1) if i in common_set]))\n",
    "x_param_2 = (\n",
    "    np.array([x for x,i in zip(x_param_2[0], good_idx_2) if i in common_set]),\n",
    "    np.array([x for x,i in zip(x_param_2[1], good_idx_2) if i in common_set]))\n",
    "z_param_1 = (\n",
    "    np.array([x for x,i in zip(z_param_1[0], good_idx_1) if i in common_set]),\n",
    "    np.array([x for x,i in zip(z_param_1[1], good_idx_1) if i in common_set]))\n",
    "z_param_2 = (\n",
    "    np.array([x for x,i in zip(z_param_2[0], good_idx_2) if i in common_set]),\n",
    "    np.array([x for x,i in zip(z_param_2[1], good_idx_2) if i in common_set]))\n",
    "\n",
    "pos_var_condition = (z_param_1[1] > 0) & (z_param_2[1] > 0)\n",
    "x_param_1 = (x_param_1[0][pos_var_condition], x_param_1[1][pos_var_condition])\n",
    "x_param_2 = (x_param_2[0][pos_var_condition], x_param_2[1][pos_var_condition])\n",
    "z_param_1 = (z_param_1[0][pos_var_condition], z_param_1[1][pos_var_condition])\n",
    "z_param_2 = (z_param_2[0][pos_var_condition], z_param_2[1][pos_var_condition])\n",
    "\n",
    "d1 = (z_param_1[1] - z_param_1[0])/z_param_1[0]**2\n",
    "d2 = (z_param_2[1] - z_param_2[0])/z_param_2[0]**2\n",
    "d1[d1 < 0] = 1e-3\n",
    "d2[d2 < 0] = 1e-3\n",
    "\n",
    "estimated_TE = np.log(x_param_2[0]) - np.log(x_param_1[0])\n",
    "estimated_TE[np.absolute(estimated_TE) < 0.1] = 0\n",
    "available_de_idxs = np.where(np.absolute(estimated_TE) > 0)[0]\n",
    "\n",
    "num_genes = x_param_1[0].shape[0]\n",
    "base_mean = np.log(x_param_1[0])\n",
    "treatment_effects = np.zeros(num_genes)\n",
    "num_de = 2000\n",
    "de_idxs = np.random.choice(available_de_idxs, num_de)\n",
    "treatment_effects[de_idxs] =  estimated_TE[de_idxs]\n",
    "\n",
    "### Generate\n",
    "\n",
    "def convert_params_nb(mu, theta):\n",
    "    \"\"\"\n",
    "    Convert mean/dispersion parameterization of a negative binomial to the ones scipy supports\n",
    "\n",
    "    See https://en.wikipedia.org/wiki/Negative_binomial_distribution#Alternative_formulations\n",
    "    \"\"\"\n",
    "    r = theta\n",
    "    var = mu + 1 / r * mu ** 2\n",
    "    p = (var - mu) / var\n",
    "    return r, 1 - p\n",
    "\n",
    "num_replicates = 2\n",
    "cell_counts = np.array([1000, 1000, 1100, 1100])\n",
    "\n",
    "num_cells = cell_counts.sum()\n",
    "expr_matrix = np.zeros((num_cells, num_genes))\n",
    "ind1_intercepts = base_mean\n",
    "ind2_intercepts = base_mean\n",
    "delta_te = stats.norm.rvs(scale=0.5, size=num_genes)\n",
    "\n",
    "relative_means = np.exp(np.vstack([\n",
    "    ind1_intercepts,\n",
    "    ind1_intercepts + treatment_effects + delta_te/2,\n",
    "    ind2_intercepts,\n",
    "    ind2_intercepts + treatment_effects - delta_te/2]))\n",
    "\n",
    "for i in range(num_genes):\n",
    "\n",
    "    gene_expr = []\n",
    "    for rep_idx in range(num_replicates*2):\n",
    "        mean = relative_means[rep_idx, i]*np.random.choice(Nc_1, cell_counts[rep_idx])\n",
    "        cells = stats.nbinom.rvs(*convert_params_nb(mean, np.mean(d1)), size=cell_counts[rep_idx])\n",
    "        gene_expr.append(cells)\n",
    "    expr_matrix[:, i] = np.concatenate(gene_expr)\n",
    "   \n",
    "\n",
    "### Perform sampling\n",
    "\n",
    "_, expr_matrix = simulate.capture_sampling(expr_matrix.astype(int), q=q, process='hyper')\n",
    "\n",
    "### Generate the dataframes\n",
    "\n",
    "group = \\\n",
    "    ['A' for i in range(cell_counts[0])] + \\\n",
    "    ['A' for i in range(cell_counts[1])] + \\\n",
    "    ['B' for i in range(cell_counts[2])] + \\\n",
    "    ['B' for i in range(cell_counts[3])]\n",
    "condition = \\\n",
    "    ['ctrl' for i in range(cell_counts[0])] + \\\n",
    "    ['stim' for i in range(cell_counts[1])] + \\\n",
    "    ['ctrl' for i in range(cell_counts[2])] + \\\n",
    "    ['stim' for i in range(cell_counts[3])]\n",
    "obs = pd.DataFrame(\n",
    "        zip(group, condition), \n",
    "        index=['cell'+str(i) for i in range(num_cells)],\n",
    "        columns=['group', 'condition'])\n",
    "var = pd.DataFrame(index=['gene'+str(i) for i in range(num_genes)])\n",
    "\n",
    "### Save AnnData\n",
    "\n",
    "anndata = sc.AnnData(\n",
    "    sp.sparse.csr_matrix(expr_matrix, dtype=float), \n",
    "    obs=obs, \n",
    "    var=var)\n",
    "de_genes = np.zeros(num_genes)\n",
    "de_genes[de_idxs] = 1\n",
    "anndata.var['is_de'] = de_genes.astype(bool)\n",
    "anndata.var['treatment_effect'] = treatment_effects\n",
    "\n",
    "anndata.write(data_path + 'de/anndata.h5ad')\n",
    "\n",
    "norm_adata = anndata.copy().copy()\n",
    "sc.pp.normalize_total(norm_adata, target_sum=1)\n",
    "norm_adata.write(data_path + 'de/norm_anndata.h5ad')\n",
    "\n",
    "expr_df = pd.DataFrame(expr_matrix, index=obs.index, columns=var.index)\n",
    "grouped = pd.concat([obs, expr_df], axis=1)\n",
    "pseudobulks = grouped.groupby(['group', 'condition'])[expr_df.columns].sum()\n",
    "pseudobulks.index = [x+'_'+y for x,y in pseudobulks.index]\n",
    "pseudobulks.T.to_csv(data_path + 'de/pseudobulks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac97512-e2ef-4059-a937-99bf72f2c25a",
   "metadata": {},
   "source": [
    "### Run DE methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ee9663-4e6a-4bee-a4d7-2f0588d767c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99f1159-7ae4-4abe-b8dd-f70c65392c15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (single_cell)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
